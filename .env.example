# Database
# Local development (Docker/PostgreSQL)
DATABASE_URL="postgresql://postgres:postgres@localhost:5432/themis?schema=public"

# Production with Supabase (takes precedence over DATABASE_URL)
# For Railway/traditional servers: Use direct connection (port 5432)
# SUPABASE_DATABASE_URL="postgresql://postgres.[project-id]:[PASSWORD]@db.xxxxx.supabase.co:5432/postgres"

# For Vercel/serverless: Use POOLED connection (port 6543) - REQUIRED for serverless!
# SUPABASE_DATABASE_URL="postgresql://postgres.[project-id]:[PASSWORD]@aws-0-[region].pooler.supabase.com:6543/postgres"

# CORS Configuration
# Comma-separated list of allowed origins (supports wildcards with *)
# Example: CORS_ORIGIN="https://yourapp.vercel.app,https://*.vercel.app,http://localhost:3000"
# Default if not set: http://localhost:3000,https://*.railway.app,https://*.up.railway.app,https://*.vercel.app
CORS_ORIGIN=""

# Auth
NEXTAUTH_URL="http://localhost:3000"
NEXTAUTH_SECRET="replace-with-strong-secret-generate-with-openssl-rand-base64-32"
GITHUB_ID="your-github-oauth-app-id"
GITHUB_SECRET="your-github-oauth-app-secret"

# LLM Provider Configuration
LLM_PROVIDER="openai"  # openai | anthropic | ollama
OPENAI_API_KEY="sk-..."
ANTHROPIC_API_KEY="sk-ant-..."
OLLAMA_BASE_URL="http://localhost:11434"

# LLM Configuration
LLM_MODEL="gpt-4-turbo-preview"  # or claude-3-opus-20240229, llama3:latest
LLM_TEMPERATURE="0.7"
LLM_MAX_TOKENS="2000"
LLM_TIMEOUT_MS="30000"

# Rate Limiting & Budget
LLM_RATE_LIMIT_PER_MINUTE="60"
LLM_DAILY_TOKEN_BUDGET="100000"
LLM_WORKSPACE_TOKEN_BUDGET="50000"

# Feature Flags
THEMIS_MAX_INITIATIVES="500"
THEMIS_MAX_CRITERIA="20"
THEMIS_MAX_REVIEWERS="10"
THEMIS_BRIEF_MAX_TOKENS="1200"
THEMIS_ENABLE_IMAGE_GENERATION="false"

# Image Generation (optional)
DALLE_API_KEY=""
STABILITY_API_KEY=""

# Observability
ENABLE_TELEMETRY="true"
OTEL_EXPORTER_OTLP_ENDPOINT=""

# Application
NODE_ENV="development"
API_PORT="4000"
WEB_PORT="3000"
